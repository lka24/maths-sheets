
\documentclass{report}
\usepackage[T1]{fontenc}
\usepackage{graphicx} % Required for inserting images
\usepackage[a4paper, margin=0.75in]{geometry}
\usepackage{amsmath}
\usepackage{tikz}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{verbatim}
\usepackage{nameref}
\usepackage{paracol}
\usepackage{tikz-cd}
\usepackage{derivative}
\usepackage{url}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{xfrac}
\usepackage{multicol}
\usepackage{caption}
\usepackage{tcolorbox}
\usepackage{soul}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{shapes.misc}
\usepackage[english]{babel}
\globalcounter{figure}

\lstdefinelanguage{R}{
  keywords={if, else, repeat, while, function, for, in, next, break},
  otherkeywords={TRUE, FALSE, NULL, Inf, NaN, NA},
  sensitive=true,
  morecomment=[l]{\#},
  morestring=[b]",
  morestring=[b]',
}

\lstdefinelanguage{Wolfram}{
  keywords={If, Else, For, While, Do, Return, Module, Block, Set, SetDelayed, Function, Table, Map, Apply, Thread, Replace, ReplaceAll},
  otherkeywords={True, False, Null, Infinity, Indeterminate},
  sensitive=true,
  morecomment=[s]{(*}{*)},
  morestring=[b]",
  keywordstyle=\color{cyan},      % Cyan for control structures
  identifierstyle=\color{white},  % White for custom variables
  emph={Sin, Cos, Tan, Log, Exp, Sqrt, Cosh, Sinh, Tanh, ArcSin, ArcCos, ArcTan, ArcSinh, ArcCosh, ArcTanh},
  emphstyle=\color{magenta},       % Magenta for built-in math functions
  commentstyle=\color{lightgray},  % Light gray for comments
  stringstyle=\color{orange},      % Orange for strings
  numberstyle=\color{yellow},      % Yellow for numbers
  literate={^}{{\textasciicircum}}1,
  xleftmargin=0pt,               % Ensure no extra indentation
}

\lstset{
  basicstyle=\ttfamily\color{white},      % White text
  keywordstyle=\color{cyan},               % Cyan keywords
  commentstyle=\color{gray},               % Gray comments
  stringstyle=\color{orange},              % Orange strings
  numberstyle=\tiny\color{lightgray},      % Light gray line numbers
  showstringspaces=false,
  breaklines=true,
  backgroundcolor=\color{black}           % Black background
}

\let\Subsectionmark\subsectionmark
\def\Subsectionname{}
\def\subsectionmark#1{\def\Subsectionname{#1}\Subsectionmark{#1}}
\fancyhead[R]{\Subsectionname}

\newtcolorbox{example}[1][]{%
    colframe=black, % Frame color
    colback=gray!7, % Background color
    fonttitle=\bfseries, % Title font styling
    title=Example
    \ifx&#1& % If first argument is empty, do nothing
    \else
        ~(#1)%
    \fi,
    sharp corners, % Box styling
}

\newtcolorbox{warning}[1][]{%
    colframe=red, % Frame color
    colback=red!7,        % Background color
    fonttitle=\bfseries,    % Title font styling
    title=Warning!%
    \ifx&#1&% Check if #1 is empty
    \else
        ~(#1)%
    \fi,
    sharp corners,          % Box styling
}

% Define a custom code block environment with verbatim
\newtcolorbox[auto counter, number within=chapter]{codeblock}[2][]{
  colback=black,
  colframe=black,
  fontupper=\ttfamily\color{white},
  fonttitle=\bfseries,
  title=Code Block \thetcbcounter: #2,
  sharp corners,
  #1
}

\newenvironment{solution}
    {\renewcommand\qedsymbol{}\begin{proof}[Solution]}
    {\end{proof}}


\newcommand{\Real}{\mathbb{R}}
\newcommand{\Expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Var}[1]{\mathrm{Var}\left[#1\right]}
\newcommand{\Prob}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\Cov}[2]{\mathrm{Cov}\left(#1,#2\right)}
\newcommand{\Rat}{\mathbb{Q}}
\newcommand{\Img}[1]{\mathrm{im}\left(#1\right)}
\newcommand{\Ker}[1]{\mathrm{ker}\left(#1\right)}
\newcommand{\ftr}[1]{\mathcal{F}\{#1\}}
\newcommand{\invftr}[1]{\mathcal{F}^{-1} \left\{ #1 \right\}}
\newcommand{\ftrcos}[1]{\mathcal{F}_c \left\{#1 \right\}}
\newcommand{\ftrsin}[1]{\mathcal{F}_s \left\{#1 \right\}}
\newcommand{\supp}[1]{\mathrm{supp}\left(#1\right)}
\newcommand{\Nat}{\mathbb{N}}
\newcommand{\Int}{\mathbb{Z}}
\newcommand{\di}[1]{\mathop{\mathrm{d}#1}}
\newcommand{\deriv}[2]{\frac{\mathrm{d} #1}{\mathrm{d}#2}}
\newcommand{\kderiv}[3]{\frac{\mathrm{d}^{#3}#1}{\mathrm{d}#2^{#3}}}
\newcommand{\set}[1]{\{ #1 \}}
\newcommand{\dls}[2]{\mathrm{L} \left( #1, #2 \right)}
\newcommand{\dus}[2]{\mathrm{U} \left( #1, #2 \right)}
\newcommand{\like}[2]{\mathrm{L}\left(#1 \vert #2 \right)}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\Span}[1]{\mathrm{Span}\left( #1 \right)}
\newcommand{\irv}[1]{\mathbb{I}_{#1}}
\newcommand{\ord}[1]{\mathrm{ord}\left(#1\right)}
\newcommand{\cycg}[1]{\left\langle #1 \right\rangle}
\newcommand{\idx}[2]{\left| #1 : #2 \right|}
\newcommand{\rss}{\mathrm{RSS}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\phi}{\varphi}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

\tcolorboxenvironment{specialtheorem}{
    colback=yellow!5,
    colframe=orange!80!black,
    before skip=10pt, after skip=10pt,
    boxrule=1pt,
    sharp corners,
    fonttitle=\bfseries,
}

\newtheorem{specialtheorem}[theorem]{Special Theorem}

\pgfplotsset{compat=newest}
\usepgfplotslibrary{colormaps}
\usetikzlibrary{patterns}

\title{Cayley-Hamilton Proof}
\author{Lorcan Addison}
\date{2025}



\begin{document}
        \begin{theorem}
            Suppose $V$ is a vector space with $\dim(V)=n$ over a field $\mathbb{F}$. Further suppose $T: V \rightarrow V$ is
            a linear map whose characteristic polynomial can be written as a product of linear factors, \textit{i.e.},
            $\chi_T (x) = \Pi_{i=1}^n (x - \lambda_i)$ for (not necessarily distinct) eigenvalues $\lambda_i$.\footnote{
                This will depend on the field. For instance, every matrix is triangularisable over $\mathbb{C}$, but
                this is certainly not so over $\mathbb{F}_p$.
            } Then there exists
            a basis $B$ of $V$ with $[T]_B$ an upper-triangular matrix.
        \end{theorem}
        \begin{proof}
            We proceed by induction on $n$, the dimension of $V$. \\

            \textbf{\ul{Base case.}} The theorem is obvious for $n = 1$ because each matrix $\begin{bmatrix} a \end{bmatrix}$
            is upper-triangular. \\

            \textbf{\ul{Inductive hypothesis.}} We assume that, for each integer $k$ with $1 \leq k < n$, the theorem holds. \\

            \textbf{\ul{Inductive step.}} Let the dimension of $V$ be $n$. Now since $\chi_T$ factorises into a product of linear
            factors, there exists an eigenvalue $\lambda \in \mathbb{F}$. Call the corresponding eigenvector $\vec{w}_1$ and
            let $W := \Span{\vec{w}_1}$. Note that, of course, $W$ is $T$-invariant. This means that we can form the quotient space
            $\sfrac{V}{W}$ and it has dimension $n - 1$.

            Recall that $\chi_T (x) = \chi_{T\vert_W} (x) \chi_{\bar{T}} (x)$ where $T\vert_W$ is the map from $W$ to $W$ with $T \vert_W (\vec{v}) = T(\vec{v})$
            and $\bar{T}$ is the map from $\sfrac{V}{W}$ to $\sfrac{V}{W}$ with $\bar{T}(W + \vec{v}) = W + T(\vec{v})$. Obviously, $T\vert_W$ and $\bar{T}$
            factorise into a product of linear factors because they divide $T$, which does so. By the inductive hypothesis there exist bases $B_W$ and $\bar{B}$
            with $[T\vert_W]_{B_W}$ and $[\bar{T}]_{\bar{B}}$ upper triangular. Let $B$ be a basis of $V$ consisting of the counterparts of $\bar{B}$ in $V$ and the
            vectors in $B_W$.

            Let us recall that we may write this linear transformation as a block matrix
            \[ [T]_B = \begin{bmatrix} [T\vert_W]_{B_W} & \ast \\ 0 & [\bar{T}]_{\bar{B}} \end{bmatrix} \]
            Because both the matrices on the diagonal are upper triangular, $[T]_B$ is upper triangular. This completes the proof.
            
        \end{proof} 
        \begin{tcolorbox}[colback=yellow!5, colframe=orange!80!black]
            The above proof also gives us a way to find the basis $B$ that reveals the triangularised matrix. 
            The steps are:

            \begin{enumerate}
                \item Find an eigenvector $\vec{w}_1$, and define $W := \Span{\vec{w}_1}$.
                \item Form $[\bar{T}]_{\bar{B}}$ and find an eigenvector $W + \vec{w}_2$ of that, then 
                let $W^\prime = \Span{\vec{w}_1, \vec{w}_2}$.
                \item Do the same thing for $\bar{\bar{T}} : \sfrac{V}{W^\prime} \rightarrow \sfrac{V}{W^\prime}$ and
                form $W^{\prime\prime}$.
                \item Repeat the above step until $W=V$. The resulting basis $\vec{w}_1, \dots, \vec{w}_n$ triangularises
                the matrix.
            \end{enumerate}
        \end{tcolorbox}

        \begin{warning}
            Remember that the theorem only works when the matrix's characteristic polynomial can be factorised into linear factors!
        \end{warning}
\end{document}